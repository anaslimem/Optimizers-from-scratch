
--- Training with Optimizer: SGD, Scheduler: ConstantLR ---
Epoch 1: loss=2.3856, acc=0.0818, lr=0.00100
Epoch 2: loss=2.3794, acc=0.0835, lr=0.00100
Epoch 3: loss=2.3732, acc=0.0845, lr=0.00100
Epoch 4: loss=2.3671, acc=0.0867, lr=0.00100
Epoch 5: loss=2.3611, acc=0.0878, lr=0.00100
Epoch 6: loss=2.3551, acc=0.0895, lr=0.00100
Epoch 7: loss=2.3493, acc=0.0911, lr=0.00100
Epoch 8: loss=2.3435, acc=0.0927, lr=0.00100
Epoch 9: loss=2.3377, acc=0.0941, lr=0.00100
Epoch 10: loss=2.3321, acc=0.0962, lr=0.00100

--- Training with Optimizer: SGD, Scheduler: StepDecay ---
Epoch 1: loss=2.3910, acc=0.1248, lr=0.00100
Epoch 2: loss=2.3834, acc=0.1261, lr=0.00100
Epoch 3: loss=2.3797, acc=0.1263, lr=0.00050
Epoch 4: loss=2.3760, acc=0.1266, lr=0.00050
Epoch 5: loss=2.3723, acc=0.1275, lr=0.00050
Epoch 6: loss=2.3705, acc=0.1283, lr=0.00025
Epoch 7: loss=2.3687, acc=0.1285, lr=0.00025
Epoch 8: loss=2.3669, acc=0.1287, lr=0.00025
Epoch 9: loss=2.3660, acc=0.1289, lr=0.00013
Epoch 10: loss=2.3651, acc=0.1293, lr=0.00013

--- Training with Optimizer: SGD, Scheduler: CosineDecay ---
Epoch 1: loss=2.4540, acc=0.1042, lr=0.00098
Epoch 2: loss=2.4483, acc=0.1049, lr=0.00090
Epoch 3: loss=2.4434, acc=0.1050, lr=0.00079
Epoch 4: loss=2.4394, acc=0.1057, lr=0.00065
Epoch 5: loss=2.4364, acc=0.1056, lr=0.00050
Epoch 6: loss=2.4343, acc=0.1053, lr=0.00035
Epoch 7: loss=2.4330, acc=0.1054, lr=0.00021
Epoch 8: loss=2.4325, acc=0.1054, lr=0.00010
Epoch 9: loss=2.4323, acc=0.1054, lr=0.00002
Epoch 10: loss=2.4323, acc=0.1054, lr=0.00000

--- Training with Optimizer: SGD, Scheduler: WarmupLR ---
Epoch 1: loss=2.5136, acc=0.0484, lr=0.00033
Epoch 2: loss=2.5087, acc=0.0496, lr=0.00067
Epoch 3: loss=2.5015, acc=0.0512, lr=0.00100
Epoch 4: loss=2.4944, acc=0.0537, lr=0.00100
Epoch 5: loss=2.4874, acc=0.0561, lr=0.00100
Epoch 6: loss=2.4805, acc=0.0578, lr=0.00100
Epoch 7: loss=2.4737, acc=0.0603, lr=0.00100
Epoch 8: loss=2.4670, acc=0.0632, lr=0.00100
Epoch 9: loss=2.4604, acc=0.0658, lr=0.00100
Epoch 10: loss=2.4538, acc=0.0682, lr=0.00100

--- Training with Optimizer: Momentum, Scheduler: ConstantLR ---
Epoch 1: loss=2.3417, acc=0.1303, lr=0.00100
Epoch 2: loss=2.2995, acc=0.1515, lr=0.00100
Epoch 3: loss=2.2590, acc=0.1711, lr=0.00100
Epoch 4: loss=2.2199, acc=0.1972, lr=0.00100
Epoch 5: loss=2.1820, acc=0.2294, lr=0.00100
Epoch 6: loss=2.1452, acc=0.2568, lr=0.00100
Epoch 7: loss=2.1094, acc=0.2902, lr=0.00100
Epoch 8: loss=2.0744, acc=0.3213, lr=0.00100
Epoch 9: loss=2.0401, acc=0.3538, lr=0.00100
Epoch 10: loss=2.0066, acc=0.3827, lr=0.00100

--- Training with Optimizer: Momentum, Scheduler: StepDecay ---
Epoch 1: loss=2.3691, acc=0.1059, lr=0.00100
Epoch 2: loss=2.3237, acc=0.1241, lr=0.00100
Epoch 3: loss=2.3020, acc=0.1329, lr=0.00050
Epoch 4: loss=2.2813, acc=0.1454, lr=0.00050
Epoch 5: loss=2.2613, acc=0.1549, lr=0.00050
Epoch 6: loss=2.2513, acc=0.1618, lr=0.00025
Epoch 7: loss=2.2416, acc=0.1673, lr=0.00025
Epoch 8: loss=2.2321, acc=0.1736, lr=0.00025
Epoch 9: loss=2.2272, acc=0.1770, lr=0.00013
Epoch 10: loss=2.2225, acc=0.1803, lr=0.00013

--- Training with Optimizer: Momentum, Scheduler: CosineDecay ---
Epoch 1: loss=2.3372, acc=0.1326, lr=0.00098
Epoch 2: loss=2.2856, acc=0.1620, lr=0.00090
Epoch 3: loss=2.2445, acc=0.1891, lr=0.00079
Epoch 4: loss=2.2128, acc=0.2149, lr=0.00065
Epoch 5: loss=2.1898, acc=0.2333, lr=0.00050
Epoch 6: loss=2.1744, acc=0.2482, lr=0.00035
Epoch 7: loss=2.1653, acc=0.2568, lr=0.00021
Epoch 8: loss=2.1611, acc=0.2607, lr=0.00010
Epoch 9: loss=2.1600, acc=0.2616, lr=0.00002
Epoch 10: loss=2.1600, acc=0.2616, lr=0.00000

--- Training with Optimizer: Momentum, Scheduler: WarmupLR ---
Epoch 1: loss=2.3230, acc=0.1370, lr=0.00033
Epoch 2: loss=2.2869, acc=0.1517, lr=0.00067
Epoch 3: loss=2.2377, acc=0.1805, lr=0.00100
Epoch 4: loss=2.1928, acc=0.2114, lr=0.00100
Epoch 5: loss=2.1515, acc=0.2444, lr=0.00100
Epoch 6: loss=2.1130, acc=0.2804, lr=0.00100
Epoch 7: loss=2.0766, acc=0.3155, lr=0.00100
Epoch 8: loss=2.0420, acc=0.3556, lr=0.00100
Epoch 9: loss=2.0087, acc=0.3947, lr=0.00100
Epoch 10: loss=1.9766, acc=0.4323, lr=0.00100

--- Training with Optimizer: RMSProp, Scheduler: ConstantLR ---
Epoch 1: loss=0.1575, acc=0.9546, lr=0.00100
Epoch 2: loss=0.1030, acc=0.9698, lr=0.00100
Epoch 3: loss=0.0896, acc=0.9739, lr=0.00100
Epoch 4: loss=0.0741, acc=0.9768, lr=0.00100
Epoch 5: loss=0.0678, acc=0.9795, lr=0.00100
Epoch 6: loss=0.0716, acc=0.9796, lr=0.00100
Epoch 7: loss=0.0696, acc=0.9789, lr=0.00100
Epoch 8: loss=0.0613, acc=0.9817, lr=0.00100
Epoch 9: loss=0.0608, acc=0.9814, lr=0.00100
Epoch 10: loss=0.0680, acc=0.9801, lr=0.00100

--- Training with Optimizer: RMSProp, Scheduler: StepDecay ---
Epoch 1: loss=0.1539, acc=0.9561, lr=0.00100
Epoch 2: loss=0.1039, acc=0.9685, lr=0.00100
Epoch 3: loss=0.0889, acc=0.9732, lr=0.00050
Epoch 4: loss=0.0826, acc=0.9750, lr=0.00050
Epoch 5: loss=0.0778, acc=0.9770, lr=0.00050
Epoch 6: loss=0.0711, acc=0.9779, lr=0.00025
Epoch 7: loss=0.0701, acc=0.9780, lr=0.00025
Epoch 8: loss=0.0656, acc=0.9793, lr=0.00025
Epoch 9: loss=0.0657, acc=0.9791, lr=0.00013
Epoch 10: loss=0.0646, acc=0.9800, lr=0.00013

--- Training with Optimizer: RMSProp, Scheduler: CosineDecay ---
Epoch 1: loss=0.1513, acc=0.9557, lr=0.00098
Epoch 2: loss=0.1069, acc=0.9689, lr=0.00090
Epoch 3: loss=0.0915, acc=0.9720, lr=0.00079
Epoch 4: loss=0.0869, acc=0.9732, lr=0.00065
Epoch 5: loss=0.0734, acc=0.9771, lr=0.00050
Epoch 6: loss=0.0734, acc=0.9783, lr=0.00035
Epoch 7: loss=0.0701, acc=0.9791, lr=0.00021
Epoch 8: loss=0.0675, acc=0.9799, lr=0.00010
Epoch 9: loss=0.0671, acc=0.9802, lr=0.00002
Epoch 10: loss=0.0671, acc=0.9802, lr=0.00000

--- Training with Optimizer: RMSProp, Scheduler: WarmupLR ---
Epoch 1: loss=0.2423, acc=0.9332, lr=0.00033
Epoch 2: loss=0.1523, acc=0.9557, lr=0.00067
Epoch 3: loss=0.1046, acc=0.9684, lr=0.00100
Epoch 4: loss=0.0975, acc=0.9699, lr=0.00100
Epoch 5: loss=0.0802, acc=0.9746, lr=0.00100
Epoch 6: loss=0.0729, acc=0.9789, lr=0.00100
Epoch 7: loss=0.0670, acc=0.9782, lr=0.00100
Epoch 8: loss=0.0702, acc=0.9791, lr=0.00100
Epoch 9: loss=0.0756, acc=0.9777, lr=0.00100
Epoch 10: loss=0.0754, acc=0.9782, lr=0.00100

--- Training with Optimizer: Adam, Scheduler: ConstantLR ---
Epoch 1: loss=0.1626, acc=0.9537, lr=0.00100
Epoch 2: loss=0.1106, acc=0.9688, lr=0.00100
Epoch 3: loss=0.0928, acc=0.9718, lr=0.00100
Epoch 4: loss=0.0789, acc=0.9739, lr=0.00100
Epoch 5: loss=0.0768, acc=0.9763, lr=0.00100
Epoch 6: loss=0.0717, acc=0.9772, lr=0.00100
Epoch 7: loss=0.0715, acc=0.9776, lr=0.00100
Epoch 8: loss=0.0712, acc=0.9777, lr=0.00100
Epoch 9: loss=0.0681, acc=0.9790, lr=0.00100
Epoch 10: loss=0.0671, acc=0.9784, lr=0.00100

--- Training with Optimizer: Adam, Scheduler: StepDecay ---
Epoch 1: loss=0.1393, acc=0.9595, lr=0.00100
Epoch 2: loss=0.0968, acc=0.9713, lr=0.00100
Epoch 3: loss=0.0798, acc=0.9750, lr=0.00050
Epoch 4: loss=0.0768, acc=0.9760, lr=0.00050
Epoch 5: loss=0.0707, acc=0.9773, lr=0.00050
Epoch 6: loss=0.0673, acc=0.9784, lr=0.00025
Epoch 7: loss=0.0665, acc=0.9786, lr=0.00025
Epoch 8: loss=0.0660, acc=0.9791, lr=0.00025
Epoch 9: loss=0.0645, acc=0.9798, lr=0.00013
Epoch 10: loss=0.0631, acc=0.9795, lr=0.00013

--- Training with Optimizer: Adam, Scheduler: CosineDecay ---
Epoch 1: loss=0.1338, acc=0.9588, lr=0.00098
Epoch 2: loss=0.1024, acc=0.9686, lr=0.00090
Epoch 3: loss=0.0826, acc=0.9741, lr=0.00079
Epoch 4: loss=0.0770, acc=0.9751, lr=0.00065
Epoch 5: loss=0.0705, acc=0.9776, lr=0.00050
Epoch 6: loss=0.0696, acc=0.9777, lr=0.00035
Epoch 7: loss=0.0669, acc=0.9792, lr=0.00021
Epoch 8: loss=0.0661, acc=0.9780, lr=0.00010
Epoch 9: loss=0.0658, acc=0.9783, lr=0.00002
Epoch 10: loss=0.0658, acc=0.9783, lr=0.00000

--- Training with Optimizer: Adam, Scheduler: WarmupLR ---
Epoch 1: loss=0.1954, acc=0.9438, lr=0.00033
Epoch 2: loss=0.1343, acc=0.9622, lr=0.00067
Epoch 3: loss=0.1044, acc=0.9687, lr=0.00100
Epoch 4: loss=0.0799, acc=0.9753, lr=0.00100
Epoch 5: loss=0.0750, acc=0.9766, lr=0.00100
Epoch 6: loss=0.0724, acc=0.9780, lr=0.00100
Epoch 7: loss=0.0620, acc=0.9801, lr=0.00100
Epoch 8: loss=0.0641, acc=0.9801, lr=0.00100
Epoch 9: loss=0.0663, acc=0.9791, lr=0.00100
Epoch 10: loss=0.0640, acc=0.9799, lr=0.00100

--- Training with Optimizer: AdamW, Scheduler: ConstantLR ---
Epoch 1: loss=0.1589, acc=0.9536, lr=0.00100
Epoch 2: loss=0.1154, acc=0.9648, lr=0.00100
Epoch 3: loss=0.0926, acc=0.9734, lr=0.00100
Epoch 4: loss=0.0787, acc=0.9756, lr=0.00100
Epoch 5: loss=0.0728, acc=0.9779, lr=0.00100
Epoch 6: loss=0.0674, acc=0.9788, lr=0.00100
Epoch 7: loss=0.0671, acc=0.9797, lr=0.00100
Epoch 8: loss=0.0655, acc=0.9799, lr=0.00100
Epoch 9: loss=0.0666, acc=0.9791, lr=0.00100
Epoch 10: loss=0.0660, acc=0.9782, lr=0.00100

--- Training with Optimizer: AdamW, Scheduler: StepDecay ---
Epoch 1: loss=0.1251, acc=0.9629, lr=0.00100
Epoch 2: loss=0.1021, acc=0.9695, lr=0.00100
Epoch 3: loss=0.0819, acc=0.9750, lr=0.00050
Epoch 4: loss=0.0767, acc=0.9760, lr=0.00050
Epoch 5: loss=0.0735, acc=0.9779, lr=0.00050
Epoch 6: loss=0.0701, acc=0.9790, lr=0.00025
Epoch 7: loss=0.0681, acc=0.9783, lr=0.00025
Epoch 8: loss=0.0669, acc=0.9792, lr=0.00025
Epoch 9: loss=0.0652, acc=0.9799, lr=0.00013
Epoch 10: loss=0.0648, acc=0.9805, lr=0.00013

--- Training with Optimizer: AdamW, Scheduler: CosineDecay ---
Epoch 1: loss=0.1303, acc=0.9610, lr=0.00098
Epoch 2: loss=0.0984, acc=0.9706, lr=0.00090
Epoch 3: loss=0.0842, acc=0.9746, lr=0.00079
Epoch 4: loss=0.0739, acc=0.9772, lr=0.00065
Epoch 5: loss=0.0704, acc=0.9780, lr=0.00050
Epoch 6: loss=0.0679, acc=0.9783, lr=0.00035
Epoch 7: loss=0.0657, acc=0.9789, lr=0.00021
Epoch 8: loss=0.0632, acc=0.9800, lr=0.00010
Epoch 9: loss=0.0635, acc=0.9792, lr=0.00002
Epoch 10: loss=0.0635, acc=0.9792, lr=0.00000

--- Training with Optimizer: AdamW, Scheduler: WarmupLR ---
Epoch 1: loss=0.1907, acc=0.9449, lr=0.00033
Epoch 2: loss=0.1258, acc=0.9623, lr=0.00067
Epoch 3: loss=0.0947, acc=0.9724, lr=0.00100
Epoch 4: loss=0.0818, acc=0.9760, lr=0.00100
Epoch 5: loss=0.0717, acc=0.9781, lr=0.00100
Epoch 6: loss=0.0697, acc=0.9783, lr=0.00100
Epoch 7: loss=0.0693, acc=0.9781, lr=0.00100
Epoch 8: loss=0.0659, acc=0.9798, lr=0.00100
Epoch 9: loss=0.0664, acc=0.9796, lr=0.00100
Epoch 10: loss=0.0632, acc=0.9809, lr=0.00100
