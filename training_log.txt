
--- Training with Optimizer: SGD, Scheduler: ConstantLR ---
Epoch 1: loss=2.3932, acc=0.0997, lr=0.00100
Epoch 2: loss=2.3877, acc=0.1015, lr=0.00100
Epoch 3: loss=2.3823, acc=0.1027, lr=0.00100
Epoch 4: loss=2.3770, acc=0.1049, lr=0.00100
Epoch 5: loss=2.3717, acc=0.1067, lr=0.00100
Epoch 6: loss=2.3664, acc=0.1093, lr=0.00100
Epoch 7: loss=2.3612, acc=0.1109, lr=0.00100
Epoch 8: loss=2.3561, acc=0.1136, lr=0.00100
Epoch 9: loss=2.3510, acc=0.1160, lr=0.00100
Epoch 10: loss=2.3459, acc=0.1180, lr=0.00100

--- Training with Optimizer: SGD, Scheduler: StepDecay ---
Epoch 1: loss=2.4002, acc=0.0802, lr=0.00100
Epoch 2: loss=2.3951, acc=0.0818, lr=0.00100
Epoch 3: loss=2.3925, acc=0.0831, lr=0.00050
Epoch 4: loss=2.3900, acc=0.0840, lr=0.00050
Epoch 5: loss=2.3875, acc=0.0851, lr=0.00050
Epoch 6: loss=2.3862, acc=0.0855, lr=0.00025
Epoch 7: loss=2.3850, acc=0.0860, lr=0.00025
Epoch 8: loss=2.3837, acc=0.0866, lr=0.00025
Epoch 9: loss=2.3831, acc=0.0867, lr=0.00013
Epoch 10: loss=2.3825, acc=0.0867, lr=0.00013

--- Training with Optimizer: SGD, Scheduler: CosineDecay ---
Epoch 1: loss=2.3467, acc=0.1050, lr=0.00098
Epoch 2: loss=2.3422, acc=0.1061, lr=0.00090
Epoch 3: loss=2.3382, acc=0.1083, lr=0.00079
Epoch 4: loss=2.3349, acc=0.1097, lr=0.00065
Epoch 5: loss=2.3324, acc=0.1111, lr=0.00050
Epoch 6: loss=2.3307, acc=0.1122, lr=0.00035
Epoch 7: loss=2.3297, acc=0.1127, lr=0.00021
Epoch 8: loss=2.3292, acc=0.1131, lr=0.00010
Epoch 9: loss=2.3291, acc=0.1132, lr=0.00002
Epoch 10: loss=2.3291, acc=0.1132, lr=0.00000

--- Training with Optimizer: SGD, Scheduler: WarmupLR ---
Epoch 1: loss=2.3427, acc=0.1488, lr=0.00033
Epoch 2: loss=2.3385, acc=0.1512, lr=0.00067
Epoch 3: loss=2.3322, acc=0.1549, lr=0.00100
Epoch 4: loss=2.3261, acc=0.1582, lr=0.00100
Epoch 5: loss=2.3200, acc=0.1612, lr=0.00100
Epoch 6: loss=2.3141, acc=0.1634, lr=0.00100
Epoch 7: loss=2.3082, acc=0.1654, lr=0.00100
Epoch 8: loss=2.3024, acc=0.1686, lr=0.00100
Epoch 9: loss=2.2967, acc=0.1717, lr=0.00100
Epoch 10: loss=2.2911, acc=0.1758, lr=0.00100

--- Training with Optimizer: Momentum, Scheduler: ConstantLR ---
Epoch 1: loss=2.2578, acc=0.1325, lr=0.00100
Epoch 2: loss=2.2147, acc=0.1714, lr=0.00100
Epoch 3: loss=2.1738, acc=0.2102, lr=0.00100
Epoch 4: loss=2.1347, acc=0.2542, lr=0.00100
Epoch 5: loss=2.0970, acc=0.2974, lr=0.00100
Epoch 6: loss=2.0606, acc=0.3396, lr=0.00100
Epoch 7: loss=2.0253, acc=0.3814, lr=0.00100
Epoch 8: loss=1.9909, acc=0.4198, lr=0.00100
Epoch 9: loss=1.9574, acc=0.4498, lr=0.00100
Epoch 10: loss=1.9246, acc=0.4800, lr=0.00100

--- Training with Optimizer: Momentum, Scheduler: StepDecay ---
Epoch 1: loss=2.2945, acc=0.1470, lr=0.00100
Epoch 2: loss=2.2464, acc=0.1843, lr=0.00100
Epoch 3: loss=2.2232, acc=0.2032, lr=0.00050
Epoch 4: loss=2.2011, acc=0.2218, lr=0.00050
Epoch 5: loss=2.1797, acc=0.2412, lr=0.00050
Epoch 6: loss=2.1690, acc=0.2488, lr=0.00025
Epoch 7: loss=2.1587, acc=0.2580, lr=0.00025
Epoch 8: loss=2.1485, acc=0.2661, lr=0.00025
Epoch 9: loss=2.1433, acc=0.2716, lr=0.00013
Epoch 10: loss=2.1383, acc=0.2764, lr=0.00013

--- Training with Optimizer: Momentum, Scheduler: CosineDecay ---
Epoch 1: loss=2.2960, acc=0.2084, lr=0.00098
Epoch 2: loss=2.2502, acc=0.2294, lr=0.00090
Epoch 3: loss=2.2127, acc=0.2522, lr=0.00079
Epoch 4: loss=2.1833, acc=0.2692, lr=0.00065
Epoch 5: loss=2.1617, acc=0.2840, lr=0.00050
Epoch 6: loss=2.1470, acc=0.2944, lr=0.00035
Epoch 7: loss=2.1384, acc=0.3006, lr=0.00021
Epoch 8: loss=2.1344, acc=0.3029, lr=0.00010
Epoch 9: loss=2.1333, acc=0.3042, lr=0.00002
Epoch 10: loss=2.1333, acc=0.3042, lr=0.00000

--- Training with Optimizer: Momentum, Scheduler: WarmupLR ---
Epoch 1: loss=2.3638, acc=0.1524, lr=0.00033
Epoch 2: loss=2.3281, acc=0.1693, lr=0.00067
Epoch 3: loss=2.2783, acc=0.1958, lr=0.00100
Epoch 4: loss=2.2318, acc=0.2291, lr=0.00100
Epoch 5: loss=2.1882, acc=0.2624, lr=0.00100
Epoch 6: loss=2.1469, acc=0.2969, lr=0.00100
Epoch 7: loss=2.1075, acc=0.3340, lr=0.00100
Epoch 8: loss=2.0696, acc=0.3696, lr=0.00100
Epoch 9: loss=2.0330, acc=0.4067, lr=0.00100
Epoch 10: loss=1.9976, acc=0.4409, lr=0.00100

--- Training with Optimizer: RMSProp, Scheduler: ConstantLR ---
Epoch 1: loss=0.1483, acc=0.9567, lr=0.00100
Epoch 2: loss=0.1046, acc=0.9697, lr=0.00100
Epoch 3: loss=0.0832, acc=0.9751, lr=0.00100
Epoch 4: loss=0.0754, acc=0.9777, lr=0.00100
Epoch 5: loss=0.0721, acc=0.9786, lr=0.00100
Epoch 6: loss=0.0739, acc=0.9782, lr=0.00100
Epoch 7: loss=0.0699, acc=0.9769, lr=0.00100
Epoch 8: loss=0.0700, acc=0.9790, lr=0.00100
Epoch 9: loss=0.0679, acc=0.9804, lr=0.00100
Epoch 10: loss=0.0677, acc=0.9803, lr=0.00100

--- Training with Optimizer: RMSProp, Scheduler: StepDecay ---
Epoch 1: loss=0.1496, acc=0.9563, lr=0.00100
Epoch 2: loss=0.1086, acc=0.9682, lr=0.00100
Epoch 3: loss=0.0861, acc=0.9754, lr=0.00050
Epoch 4: loss=0.0798, acc=0.9754, lr=0.00050
Epoch 5: loss=0.0719, acc=0.9783, lr=0.00050
Epoch 6: loss=0.0712, acc=0.9779, lr=0.00025
Epoch 7: loss=0.0683, acc=0.9800, lr=0.00025
Epoch 8: loss=0.0687, acc=0.9791, lr=0.00025
Epoch 9: loss=0.0670, acc=0.9789, lr=0.00013
Epoch 10: loss=0.0653, acc=0.9803, lr=0.00013

--- Training with Optimizer: RMSProp, Scheduler: CosineDecay ---
Epoch 1: loss=0.1537, acc=0.9538, lr=0.00098
Epoch 2: loss=0.1114, acc=0.9671, lr=0.00090
Epoch 3: loss=0.0910, acc=0.9732, lr=0.00079
Epoch 4: loss=0.0833, acc=0.9733, lr=0.00065
Epoch 5: loss=0.0728, acc=0.9783, lr=0.00050
Epoch 6: loss=0.0712, acc=0.9777, lr=0.00035
Epoch 7: loss=0.0717, acc=0.9784, lr=0.00021
Epoch 8: loss=0.0673, acc=0.9791, lr=0.00010
Epoch 9: loss=0.0669, acc=0.9792, lr=0.00002
Epoch 10: loss=0.0669, acc=0.9792, lr=0.00000

--- Training with Optimizer: RMSProp, Scheduler: WarmupLR ---
Epoch 1: loss=0.2419, acc=0.9303, lr=0.00033
Epoch 2: loss=0.1544, acc=0.9571, lr=0.00067
Epoch 3: loss=0.1092, acc=0.9688, lr=0.00100
Epoch 4: loss=0.0869, acc=0.9737, lr=0.00100
Epoch 5: loss=0.0743, acc=0.9770, lr=0.00100
Epoch 6: loss=0.0739, acc=0.9778, lr=0.00100
Epoch 7: loss=0.0715, acc=0.9782, lr=0.00100
Epoch 8: loss=0.0734, acc=0.9780, lr=0.00100
Epoch 9: loss=0.0685, acc=0.9798, lr=0.00100
Epoch 10: loss=0.0649, acc=0.9810, lr=0.00100

--- Training with Optimizer: Adam, Scheduler: ConstantLR ---
Epoch 1: loss=0.1595, acc=0.9537, lr=0.00100
Epoch 2: loss=0.1124, acc=0.9662, lr=0.00100
Epoch 3: loss=0.0857, acc=0.9736, lr=0.00100
Epoch 4: loss=0.0751, acc=0.9758, lr=0.00100
Epoch 5: loss=0.0680, acc=0.9782, lr=0.00100
Epoch 6: loss=0.0687, acc=0.9792, lr=0.00100
Epoch 7: loss=0.0655, acc=0.9796, lr=0.00100
Epoch 8: loss=0.0619, acc=0.9803, lr=0.00100
Epoch 9: loss=0.0641, acc=0.9802, lr=0.00100
Epoch 10: loss=0.0669, acc=0.9794, lr=0.00100

--- Training with Optimizer: Adam, Scheduler: StepDecay ---
Epoch 1: loss=0.1291, acc=0.9625, lr=0.00100
Epoch 2: loss=0.0948, acc=0.9716, lr=0.00100
Epoch 3: loss=0.0809, acc=0.9743, lr=0.00050
Epoch 4: loss=0.0768, acc=0.9763, lr=0.00050
Epoch 5: loss=0.0715, acc=0.9775, lr=0.00050
Epoch 6: loss=0.0692, acc=0.9783, lr=0.00025
Epoch 7: loss=0.0661, acc=0.9788, lr=0.00025
Epoch 8: loss=0.0645, acc=0.9792, lr=0.00025
Epoch 9: loss=0.0634, acc=0.9800, lr=0.00013
Epoch 10: loss=0.0626, acc=0.9796, lr=0.00013

--- Training with Optimizer: Adam, Scheduler: CosineDecay ---
Epoch 1: loss=0.1312, acc=0.9617, lr=0.00098
Epoch 2: loss=0.1057, acc=0.9666, lr=0.00090
Epoch 3: loss=0.0817, acc=0.9742, lr=0.00079
Epoch 4: loss=0.0745, acc=0.9758, lr=0.00065
Epoch 5: loss=0.0720, acc=0.9765, lr=0.00050
Epoch 6: loss=0.0671, acc=0.9787, lr=0.00035
Epoch 7: loss=0.0664, acc=0.9792, lr=0.00021
Epoch 8: loss=0.0651, acc=0.9799, lr=0.00010
Epoch 9: loss=0.0647, acc=0.9799, lr=0.00002
Epoch 10: loss=0.0647, acc=0.9799, lr=0.00000

--- Training with Optimizer: Adam, Scheduler: WarmupLR ---
Epoch 1: loss=0.1952, acc=0.9435, lr=0.00033
Epoch 2: loss=0.1279, acc=0.9618, lr=0.00067
Epoch 3: loss=0.1010, acc=0.9687, lr=0.00100
Epoch 4: loss=0.0854, acc=0.9739, lr=0.00100
Epoch 5: loss=0.0758, acc=0.9758, lr=0.00100
Epoch 6: loss=0.0700, acc=0.9791, lr=0.00100
Epoch 7: loss=0.0673, acc=0.9794, lr=0.00100
Epoch 8: loss=0.0657, acc=0.9803, lr=0.00100
Epoch 9: loss=0.0685, acc=0.9791, lr=0.00100
Epoch 10: loss=0.0685, acc=0.9778, lr=0.00100

--- Training with Optimizer: AdamW, Scheduler: ConstantLR ---
Epoch 1: loss=0.1482, acc=0.9573, lr=0.00100
Epoch 2: loss=0.1085, acc=0.9677, lr=0.00100
Epoch 3: loss=0.0868, acc=0.9728, lr=0.00100
Epoch 4: loss=0.0829, acc=0.9756, lr=0.00100
Epoch 5: loss=0.0679, acc=0.9795, lr=0.00100
Epoch 6: loss=0.0624, acc=0.9806, lr=0.00100
Epoch 7: loss=0.0634, acc=0.9795, lr=0.00100
Epoch 8: loss=0.0620, acc=0.9813, lr=0.00100
Epoch 9: loss=0.0619, acc=0.9798, lr=0.00100
Epoch 10: loss=0.0634, acc=0.9806, lr=0.00100

--- Training with Optimizer: AdamW, Scheduler: StepDecay ---
Epoch 1: loss=0.1295, acc=0.9611, lr=0.00100
Epoch 2: loss=0.0961, acc=0.9712, lr=0.00100
Epoch 3: loss=0.0833, acc=0.9749, lr=0.00050
Epoch 4: loss=0.0769, acc=0.9774, lr=0.00050
Epoch 5: loss=0.0727, acc=0.9781, lr=0.00050
Epoch 6: loss=0.0705, acc=0.9787, lr=0.00025
Epoch 7: loss=0.0669, acc=0.9800, lr=0.00025
Epoch 8: loss=0.0678, acc=0.9794, lr=0.00025
Epoch 9: loss=0.0658, acc=0.9804, lr=0.00013
Epoch 10: loss=0.0650, acc=0.9801, lr=0.00013

--- Training with Optimizer: AdamW, Scheduler: CosineDecay ---
Epoch 1: loss=0.1344, acc=0.9606, lr=0.00098
Epoch 2: loss=0.0945, acc=0.9719, lr=0.00090
Epoch 3: loss=0.0804, acc=0.9772, lr=0.00079
Epoch 4: loss=0.0750, acc=0.9785, lr=0.00065
Epoch 5: loss=0.0687, acc=0.9791, lr=0.00050
Epoch 6: loss=0.0662, acc=0.9794, lr=0.00035
Epoch 7: loss=0.0633, acc=0.9809, lr=0.00021
Epoch 8: loss=0.0636, acc=0.9808, lr=0.00010
Epoch 9: loss=0.0630, acc=0.9811, lr=0.00002
Epoch 10: loss=0.0630, acc=0.9811, lr=0.00000

--- Training with Optimizer: AdamW, Scheduler: WarmupLR ---
Epoch 1: loss=0.2041, acc=0.9417, lr=0.00033
Epoch 2: loss=0.1290, acc=0.9625, lr=0.00067
Epoch 3: loss=0.1043, acc=0.9686, lr=0.00100
Epoch 4: loss=0.0863, acc=0.9745, lr=0.00100
Epoch 5: loss=0.0828, acc=0.9742, lr=0.00100
Epoch 6: loss=0.0668, acc=0.9790, lr=0.00100
Epoch 7: loss=0.0690, acc=0.9774, lr=0.00100
Epoch 8: loss=0.0655, acc=0.9785, lr=0.00100
Epoch 9: loss=0.0710, acc=0.9781, lr=0.00100
Epoch 10: loss=0.0649, acc=0.9798, lr=0.00100
